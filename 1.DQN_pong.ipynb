{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from mxboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from IPython.display import clear_output\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_atari, wrap_deepmind, wrap_mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"PongNoFrameskip-v4\"\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env,frame_stack=True)\n",
    "env    = wrap_mxnet(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Block):\n",
    "    def __init__(self, input_shape, n_actions, **kwargs):\n",
    "        super(DQN, self).__init__(**kwargs)\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.conv1 = nn.Conv2D(32, 8, 4, in_channels=input_shape[0])\n",
    "            self.bn1 = nn.BatchNorm()\n",
    "            self.conv2 = nn.Conv2D(64, 4, 2, in_channels=32)\n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            self.conv3 = nn.Conv2D(64, 3, 1, in_channels=64)\n",
    "            self.bn3 = nn.BatchNorm()\n",
    "            self.fc1 = nn.Dense(512)\n",
    "            self.fc2 = nn.Dense(n_actions, in_units=512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = nd.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = nd.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = nd.relu(out)\n",
    "        out = nd.reshape(out, shape=(x.shape[0],-1))\n",
    "        out = self.fc1(out)\n",
    "        out = nd.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "    def act(self, state, epsilon, ctx):\n",
    "        if random.random() > epsilon:\n",
    "            state = nd.array(np.float32(state), ctx=ctx).expand_dims(0) / 255.0\n",
    "            q_value = self.forward(state)\n",
    "            action = nd.argmax(q_value, axis=1)\n",
    "            action = int(action.asnumpy())\n",
    "        else:\n",
    "            action = random.randrange(env.action_space.n)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size, net, loss_fn, ctx):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = nd.array((np.float32(state)), ctx=ctx) / 255.0\n",
    "    next_state = nd.array(np.float32(next_state), ctx=ctx)\n",
    "    action     = nd.array((action), ctx=ctx)\n",
    "    reward     = nd.array((reward), ctx=ctx)\n",
    "    done       = nd.array((done), ctx=ctx)\n",
    "\n",
    "    q_values      = net(state)\n",
    "    next_q_values = net(next_state)\n",
    "    \n",
    "    q_values = nd.gather_nd(q_values, nd.stack(nd.arange(action.shape[0], ctx=ctx).expand_dims(-1),action.expand_dims(-1), axis=0))\n",
    "    next_q_value     = next_q_values.max(1)\n",
    "    \n",
    "    q_values = q_values.squeeze()\n",
    "    next_q_value = next_q_value.squeeze()\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    print(q_values.shape)\n",
    "    print(expected_q_value.shape)\n",
    "    loss = loss_fn(q_values, expected_q_value)\n",
    "#     loss = nd.power(q_values - expected_q_value,2).mean()\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_initial = 10000\n",
    "replay_buffer = ReplayBuffer(100000)\n",
    "\n",
    "net = DQN(env.observation_space.shape, env.action_space.n)\n",
    "net.initialize(ctx=ctx)\n",
    "loss_fn = gluon.loss.L2Loss()\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer='adam', optimizer_params={'learning_rate':0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.02\n",
    "epsilon_decay = 30000\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 1400000\n",
    "batch_size = 32\n",
    "gamma      = 0.99\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()\n",
    "writer = SummaryWriter(logdir='./logs',filename_suffix=\"_DQN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870: done 1 games, mean reward -21.000, reward -21.000, eps 0.97\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f201afb898b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#     if frame_idx % 10000 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1990\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1970\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1972\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "current_best = 0.0\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = net.act(state, epsilon, ctx)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        writer.add_scalar(\"reward\", episode_reward, frame_idx)  \n",
    "        mean_reward = np.mean(all_rewards[-100:])\n",
    "        print(\"%d: done %d games, mean reward %.3f, reward %.3f, eps %.2f\" % (\n",
    "                frame_idx, len(all_rewards), mean_reward, episode_reward, epsilon,\n",
    "            ))\n",
    "        if current_best < mean_reward:\n",
    "            print(\"save current best model\")\n",
    "            net.save_parameters('./models/cartpole_best_model')\n",
    "            current_best = mean_reward\n",
    "        episode_reward = 0\n",
    "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
    "        writer.add_scalar(\"mean_reward\", mean_reward, frame_idx)  \n",
    "        \n",
    "        \n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        with autograd.record():\n",
    "#             print(\"compute loss\")\n",
    "            loss = compute_td_loss(batch_size, net, loss_fn, ctx)\n",
    "            loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "        losses.append(loss.sum().asscalar())\n",
    "        writer.add_scalar(\"loss\", loss.mean().asscalar(), frame_idx) \n",
    "#     if frame_idx % 10000 == 0:\n",
    "#         plot(frame_idx, all_rewards, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = nd.array((np.float32(state)), ctx=ctx) / 255.0\n",
    "    next_state = nd.array(np.float32(next_state), ctx=ctx)\n",
    "    action     = nd.array((action), ctx=ctx)\n",
    "    reward     = nd.array((reward), ctx=ctx)\n",
    "    done       = nd.array((done), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   ...\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]]]\n",
       "\n",
       "\n",
       " [[[0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   ...\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]]]\n",
       "\n",
       "\n",
       " [[[0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   ...\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   ...\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]]]\n",
       "\n",
       "\n",
       " [[[0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   ...\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]]]\n",
       "\n",
       "\n",
       " [[[0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.20392157 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   ...\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]\n",
       "   [0.34117648 0.34117648 0.34117648 ... 0.9254902  0.9254902\n",
       "    0.9254902 ]]]]\n",
       "<NDArray 64x1x84x84 @gpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    q_values      = net(state)\n",
    "    next_q_values = net(next_state)\n",
    "    \n",
    "#     q_values = nd.gather_nd(q_values, nd.stack(nd.arange(action.shape[0], ctx=ctx).expand_dims(-1),action.expand_dims(-1), axis=0))\n",
    "#     next_q_value     = next_q_values.max(1)\n",
    "#     expected_q_value = reward + gamma * next_q_value * (1 - done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.01308831  0.02949993  0.13193344 -0.09351277  0.46219692  0.07861875]\n",
       " [-0.01264067  0.02947327  0.13350035 -0.09446591  0.46111673  0.0793374 ]\n",
       " [-0.01275302  0.02911252  0.13252924 -0.09362247  0.46371642  0.07859968]\n",
       " [-0.01360997  0.02901225  0.13291612 -0.09286225  0.46156415  0.07799529]\n",
       " [-0.01271808  0.02985693  0.13179749 -0.09364564  0.46239865  0.07754089]\n",
       " [-0.0155503   0.03114699  0.13334677 -0.09410661  0.46289864  0.08036682]\n",
       " [-0.01273784  0.02844112  0.1362626  -0.09261388  0.46247298  0.07853465]\n",
       " [-0.01379248  0.02906224  0.13446493 -0.09217975  0.4618057   0.07770078]\n",
       " [-0.01445401  0.02872759  0.13348524 -0.0936028   0.461296    0.08012594]\n",
       " [-0.01443531  0.02836615  0.13265958 -0.09343564  0.4619497   0.07793523]\n",
       " [-0.01370101  0.02943321  0.13264008 -0.09226813  0.4635886   0.08097759]\n",
       " [-0.01408887  0.02825195  0.13299163 -0.09351309  0.46188277  0.07867248]\n",
       " [-0.01215731  0.03016526  0.13175145 -0.09391582  0.46169758  0.07704474]\n",
       " [-0.01395422  0.03199781  0.13352862 -0.09326191  0.462777    0.07920368]\n",
       " [-0.01442034  0.02841271  0.13212702 -0.09292392  0.46184373  0.07789187]\n",
       " [-0.01293974  0.02881501  0.13249242 -0.09297755  0.46171343  0.07780971]\n",
       " [-0.01453531  0.02894381  0.13259669 -0.09314231  0.46116197  0.0780472 ]\n",
       " [-0.01388304  0.03102152  0.13368975 -0.09535962  0.46164826  0.08026507]\n",
       " [-0.01340012  0.02857095  0.13274193 -0.09179532  0.4607229   0.07673557]\n",
       " [-0.01279651  0.0298419   0.13295424 -0.0939495   0.46138155  0.07766081]\n",
       " [-0.01324242  0.02755402  0.13291766 -0.09225074  0.4617264   0.07916044]\n",
       " [-0.0130621   0.02874348  0.13283585 -0.0928992   0.46179265  0.07777484]\n",
       " [-0.01272021  0.030177    0.13244198 -0.09398049  0.46191385  0.07752685]\n",
       " [-0.01267502  0.02966689  0.13265339 -0.09446521  0.46166617  0.07823001]\n",
       " [-0.01322091  0.02948898  0.13321716 -0.09328644  0.46175802  0.07935984]\n",
       " [-0.01449053  0.03011356  0.13474692 -0.09160601  0.46164453  0.07888533]\n",
       " [-0.01288527  0.02978161  0.13288292 -0.09375136  0.4619049   0.07771789]\n",
       " [-0.01458463  0.0286066   0.13240604 -0.09325534  0.46329808  0.07847409]\n",
       " [-0.01373354  0.02965342  0.13216268 -0.09333637  0.46233422  0.07838354]\n",
       " [-0.01265807  0.02863374  0.13282777 -0.09314058  0.46110937  0.07799982]\n",
       " [-0.01386082  0.02971482  0.1327119  -0.09341434  0.46266365  0.07873222]\n",
       " [-0.01493665  0.02913547  0.13316216 -0.09322649  0.46326262  0.07925157]\n",
       " [-0.01336299  0.02884192  0.13280994 -0.09299843  0.46147045  0.07797657]\n",
       " [-0.01248598  0.02900095  0.13233773 -0.09297051  0.46224147  0.07877655]\n",
       " [-0.01229654  0.02896424  0.13325295 -0.094295    0.4612153   0.07909182]\n",
       " [-0.01290327  0.02838303  0.13256492 -0.09458973  0.46115208  0.07890768]\n",
       " [-0.01154816  0.02986053  0.1328615  -0.09481248  0.46109793  0.07804959]\n",
       " [-0.01344021  0.02803453  0.13333605 -0.0927595   0.46166152  0.07807539]\n",
       " [-0.01241404  0.03048655  0.13215627 -0.09507397  0.46213388  0.07782365]\n",
       " [-0.01369789  0.0294382   0.13215059 -0.09279336  0.4619915   0.07801004]\n",
       " [-0.0146943   0.02972599  0.1327418  -0.09314202  0.46175218  0.0780092 ]\n",
       " [-0.01330043  0.027109    0.13292168 -0.09391567  0.46162713  0.07797895]\n",
       " [-0.01273686  0.02754261  0.13178231 -0.09172933  0.46141022  0.07794429]\n",
       " [-0.01327719  0.02927941  0.1324178  -0.09323408  0.46207103  0.07818969]\n",
       " [-0.0136119   0.02813409  0.13397218 -0.09162241  0.46199185  0.07731377]\n",
       " [-0.01322946  0.03102346  0.13326246 -0.09497318  0.4622097   0.07825123]\n",
       " [-0.01335609  0.02966107  0.13297011 -0.09340243  0.4618419   0.07780345]\n",
       " [-0.01338041  0.02958967  0.13313377 -0.09291623  0.46184504  0.07776977]\n",
       " [-0.01587884  0.02887231  0.13320385 -0.09354763  0.46272954  0.07944871]\n",
       " [-0.01227754  0.02877508  0.13418731 -0.09244753  0.46083388  0.07705601]\n",
       " [-0.01330717  0.02936779  0.13202138 -0.09407279  0.46222275  0.07834058]\n",
       " [-0.0152884   0.02701223  0.13126774 -0.0930244   0.463687    0.07833843]\n",
       " [-0.01415183  0.02874137  0.13166688 -0.09345719  0.46173778  0.07862045]\n",
       " [-0.01347144  0.02940685  0.13288327 -0.09376786  0.46205378  0.07840838]\n",
       " [-0.01378612  0.02867521  0.13239054 -0.09310081  0.46190396  0.07784604]\n",
       " [-0.01360997  0.02901225  0.13291612 -0.09286225  0.46156415  0.07799529]\n",
       " [-0.01132116  0.03045519  0.1307479  -0.09500454  0.46290314  0.07760407]\n",
       " [-0.01253502  0.03005608  0.13294801 -0.09382588  0.46067736  0.07890727]\n",
       " [-0.01453933  0.02850114  0.1335352  -0.09377529  0.46218073  0.07770826]\n",
       " [-0.01395054  0.02913471  0.13343401 -0.0944903   0.46250886  0.07720803]\n",
       " [-0.01335087  0.02951033  0.13319369 -0.09293008  0.46178576  0.07831483]\n",
       " [-0.01161538  0.02919926  0.13195808 -0.09515333  0.46120632  0.07842351]\n",
       " [-0.01323756  0.02804939  0.13529141 -0.09351689  0.4624952   0.07783155]\n",
       " [-0.01398739  0.02844168  0.13251422 -0.09368235  0.46102506  0.07756959]]\n",
       "<NDArray 64x6 @gpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    q_values = nd.gather_nd(q_values, nd.stack(nd.arange(action.shape[0], ctx=ctx).expand_dims(-1),action.expand_dims(-1), axis=0))\n",
    "    next_q_value     = next_q_values.max(1)\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.07861875]\n",
       " [ 0.0793374 ]\n",
       " [ 0.46371642]\n",
       " [ 0.02901225]\n",
       " [ 0.46239865]\n",
       " [-0.0155503 ]\n",
       " [-0.09261388]\n",
       " [-0.01379248]\n",
       " [ 0.461296  ]\n",
       " [-0.01443531]\n",
       " [-0.01370101]\n",
       " [-0.01408887]\n",
       " [-0.09391582]\n",
       " [ 0.462777  ]\n",
       " [ 0.46184373]\n",
       " [ 0.46171343]\n",
       " [ 0.02894381]\n",
       " [ 0.13368975]\n",
       " [ 0.13274193]\n",
       " [ 0.0298419 ]\n",
       " [ 0.02755402]\n",
       " [ 0.13283585]\n",
       " [-0.09398049]\n",
       " [ 0.07823001]\n",
       " [-0.01322091]\n",
       " [ 0.03011356]\n",
       " [-0.01288527]\n",
       " [-0.09325534]\n",
       " [ 0.02965342]\n",
       " [-0.09314058]\n",
       " [-0.01386082]\n",
       " [-0.09322649]\n",
       " [ 0.13280994]\n",
       " [-0.09297051]\n",
       " [-0.01229654]\n",
       " [ 0.46115208]\n",
       " [-0.09481248]\n",
       " [ 0.13333605]\n",
       " [ 0.07782365]\n",
       " [-0.01369789]\n",
       " [ 0.1327418 ]\n",
       " [ 0.46162713]\n",
       " [-0.09172933]\n",
       " [ 0.46207103]\n",
       " [ 0.07731377]\n",
       " [ 0.07825123]\n",
       " [ 0.07780345]\n",
       " [-0.01338041]\n",
       " [ 0.02887231]\n",
       " [ 0.13418731]\n",
       " [ 0.13202138]\n",
       " [ 0.463687  ]\n",
       " [ 0.07862045]\n",
       " [ 0.07840838]\n",
       " [ 0.02867521]\n",
       " [ 0.02901225]\n",
       " [ 0.46290314]\n",
       " [-0.01253502]\n",
       " [ 0.46218073]\n",
       " [ 0.46250886]\n",
       " [-0.09293008]\n",
       " [ 0.07842351]\n",
       " [-0.01323756]\n",
       " [ 0.13251422]]\n",
       "<NDArray 64x1 @gpu(0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = gluon.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[13.505692]\n",
       "<NDArray 1 @gpu(0)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(q_values, expected_q_value).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.42250335]\n",
       "<NDArray 1 @gpu(0)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.power(q_values - expected_q_value,2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nd.power(q_values - expected_q_value,2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[128.41974]\n",
       "<NDArray 1 @gpu(0)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(q_values, expected_q_value).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[ 3.32642882e-03  1.02666570e-02  2.26427913e-02 ...  4.60287696e-03\n",
       "    -1.99091937e-02 -1.99267287e-02]\n",
       "   [ 3.27065517e-03  1.06781907e-02  2.27930583e-02 ...  4.76535875e-03\n",
       "    -1.98565964e-02 -1.94186009e-02]\n",
       "   [ 2.77602836e-03  1.04552601e-02  2.26033293e-02 ...  4.75762039e-03\n",
       "    -2.00518426e-02 -1.96249709e-02]\n",
       "   ...\n",
       "   [ 7.85774842e-04  1.06070992e-02  2.29748543e-02 ...  4.91922488e-03\n",
       "    -1.95663646e-02 -1.95613652e-02]\n",
       "   [ 9.90324887e-04  1.05871679e-02  2.30480842e-02 ...  4.78323922e-03\n",
       "    -1.93662345e-02 -1.94529854e-02]\n",
       "   [-2.71517783e-05  8.45097844e-03  2.14985535e-02 ...  4.71983105e-03\n",
       "    -1.95656475e-02 -1.99426636e-02]]]\n",
       "\n",
       "\n",
       " [[[ 1.99049129e-03  7.39674037e-03  3.48120555e-03 ... -8.61275941e-04\n",
       "    -2.10155174e-03  3.75435222e-04]\n",
       "   [-4.91639785e-03  9.54594929e-04 -2.20501982e-03 ...  1.37664750e-03\n",
       "     6.42713159e-04  1.40175736e-03]\n",
       "   [-6.87667681e-03 -6.84650615e-04 -2.79970095e-03 ...  2.07509287e-03\n",
       "     1.74485496e-03  2.10008491e-03]\n",
       "   ...\n",
       "   [-1.24522299e-02 -6.84957765e-03 -9.61259659e-03 ... -5.51891373e-03\n",
       "    -8.51898268e-03 -7.36016361e-03]\n",
       "   [-1.51103754e-02 -9.18340124e-03 -8.57196096e-03 ... -3.46954167e-03\n",
       "    -6.82304148e-03 -6.64565712e-03]\n",
       "   [-1.23484991e-02 -8.03141203e-03 -3.39720398e-04 ...  1.00714341e-03\n",
       "    -2.66823452e-03 -8.83089844e-03]]]\n",
       "\n",
       "\n",
       " [[[ 3.12025845e-03  3.76485358e-03  9.06832924e-04 ...  1.52322790e-03\n",
       "     2.56692851e-03  3.37659172e-03]\n",
       "   [ 1.29365991e-03  1.36594684e-03 -9.84712620e-04 ... -1.82273754e-04\n",
       "     8.89930059e-04  1.80670968e-03]\n",
       "   [-1.29592838e-04  9.43829509e-05 -2.00987211e-03 ... -3.79202538e-04\n",
       "     4.68899147e-04  5.81352855e-04]\n",
       "   ...\n",
       "   [ 1.71885081e-03  1.60201616e-03 -3.84959625e-04 ... -3.56296659e-04\n",
       "     2.30847858e-04 -3.67078581e-04]\n",
       "   [ 8.35360610e-04  9.06778732e-05 -8.83161905e-04 ... -3.68955429e-04\n",
       "     5.03862975e-04 -6.99273078e-05]\n",
       "   [ 5.87248593e-04 -4.10713139e-04 -2.04468938e-03 ... -6.49542897e-04\n",
       "    -3.64069128e-05  6.02380838e-04]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[-9.27076442e-04  5.85776148e-03  1.89007763e-02 ...  6.72002416e-03\n",
       "    -1.27859795e-02 -1.24391261e-02]\n",
       "   [-5.42435562e-04  9.49216634e-03  2.28284374e-02 ...  9.90078505e-03\n",
       "    -9.16300155e-03 -9.87870805e-03]\n",
       "   [-1.52169482e-03  9.02306195e-03  2.19702534e-02 ...  1.00557283e-02\n",
       "    -8.86113942e-03 -9.36028734e-03]\n",
       "   ...\n",
       "   [-3.38586426e-04  8.19761585e-03  2.11355351e-02 ...  8.33965279e-03\n",
       "    -1.00049200e-02 -1.04716113e-02]\n",
       "   [-2.53069447e-06  7.62044638e-03  2.05521360e-02 ...  6.88552670e-03\n",
       "    -1.19109834e-02 -1.26271853e-02]\n",
       "   [-3.96560133e-03  1.98581140e-03  1.64837632e-02 ...  5.99808339e-03\n",
       "    -1.28166433e-02 -1.39336102e-02]]]\n",
       "\n",
       "\n",
       " [[[ 5.85787464e-03  3.13741295e-03 -2.30121054e-03 ...  6.46043569e-04\n",
       "     5.71918022e-03  7.64236460e-03]\n",
       "   [ 6.97248988e-03  2.17089779e-03 -1.32154115e-03 ...  2.65959464e-03\n",
       "     7.74845248e-03  7.43431039e-03]\n",
       "   [ 7.84904324e-03  3.16240825e-03  5.16455621e-05 ...  3.75847705e-03\n",
       "     8.27028975e-03  7.72373891e-03]\n",
       "   ...\n",
       "   [ 1.09516345e-02  6.58885622e-03 -4.84254211e-04 ...  3.51183023e-03\n",
       "     8.21639225e-03  6.55256724e-03]\n",
       "   [ 9.92178917e-03  6.26860326e-03 -1.03077851e-03 ...  4.47737239e-03\n",
       "     9.01051238e-03  7.21045909e-03]\n",
       "   [ 8.21792334e-03  4.67040250e-03 -8.89189541e-05 ...  2.74418853e-03\n",
       "     7.37748109e-03  5.73881436e-03]]]\n",
       "\n",
       "\n",
       " [[[-5.75718004e-03 -6.51399419e-03 -7.88104162e-03 ... -1.01382947e-02\n",
       "    -1.73645020e-02 -1.78954564e-02]\n",
       "   [-7.17218360e-03 -6.41208142e-03 -7.84467068e-03 ... -9.45448969e-03\n",
       "    -1.63598303e-02 -1.70103926e-02]\n",
       "   [-7.50669185e-03 -6.85035624e-03 -8.40134453e-03 ... -8.94214492e-03\n",
       "    -1.65488385e-02 -1.68526024e-02]\n",
       "   ...\n",
       "   [-3.91976163e-03 -4.76796553e-03 -6.80346135e-03 ... -9.52470675e-03\n",
       "    -1.64921954e-02 -1.64454747e-02]\n",
       "   [-3.35471379e-03 -4.12878394e-03 -6.40098052e-03 ... -9.34977550e-03\n",
       "    -1.64230242e-02 -1.58924460e-02]\n",
       "   [-6.40487205e-03 -6.96213683e-03 -8.21848586e-03 ... -9.72375087e-03\n",
       "    -1.72588006e-02 -1.71814766e-02]]]]\n",
       "<NDArray 32x1x8x8 @gpu(0)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
